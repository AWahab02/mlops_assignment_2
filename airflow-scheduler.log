2024-05-12 20:20:15,989 INFO - Task context logging is enabled
2024-05-12 20:20:15,990 INFO - Loaded executor: SequentialExecutor
2024-05-12 20:20:16,066 INFO - Starting the scheduler
2024-05-12 20:20:16,066 INFO - Processing each file at most -1 times
2024-05-12 20:20:16,070 INFO - Launched DagFileProcessorManager with pid: 9080
2024-05-12 20:20:16,072 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-12 20:20:16,075 INFO - Configured default timezone UTC
2024-05-12 20:25:16,226 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-12 20:27:22,103 INFO - Exiting gracefully upon receiving signal 15
2024-05-12 20:27:23,107 INFO - Sending Signals.SIGTERM to group 9080. PIDs of all processes in the group: [9080]
2024-05-12 20:27:23,107 INFO - Sending the signal Signals.SIGTERM to group 9080
2024-05-12 20:27:23,200 INFO - Process psutil.Process(pid=9080, status='terminated', exitcode=0, started='20:20:15') (9080) terminated with exit code 0
2024-05-12 20:27:23,202 INFO - Sending Signals.SIGTERM to group 9080. PIDs of all processes in the group: []
2024-05-12 20:27:23,202 INFO - Sending the signal Signals.SIGTERM to group 9080
2024-05-12 20:27:23,203 INFO - Sending the signal Signals.SIGTERM to process 9080 as process group is missing.
2024-05-12 20:27:23,203 INFO - Exited execute loop
2024-05-12 20:27:26,496 INFO - Task context logging is enabled
2024-05-12 20:27:26,497 INFO - Loaded executor: SequentialExecutor
2024-05-12 20:27:26,528 INFO - Starting the scheduler
2024-05-12 20:27:26,529 INFO - Processing each file at most -1 times
2024-05-12 20:27:26,532 INFO - Launched DagFileProcessorManager with pid: 11716
2024-05-12 20:27:26,534 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-12 20:27:26,536 INFO - Configured default timezone UTC
2024-05-12 20:30:04,283 INFO - 1 tasks up for execution:
	<TaskInstance: extract_transform_load_data_dag.extract_data manual__2024-05-12T15:30:03.761985+00:00 [scheduled]>
2024-05-12 20:30:04,283 INFO - DAG extract_transform_load_data_dag has 0/16 running and queued tasks
2024-05-12 20:30:04,283 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_transform_load_data_dag.extract_data manual__2024-05-12T15:30:03.761985+00:00 [scheduled]>
2024-05-12 20:30:04,285 INFO - Sending TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='extract_data', run_id='manual__2024-05-12T15:30:03.761985+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-05-12 20:30:04,285 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'extract_data', 'manual__2024-05-12T15:30:03.761985+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:30:04,302 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'extract_data', 'manual__2024-05-12T15:30:03.761985+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:30:27,025 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='extract_data', run_id='manual__2024-05-12T15:30:03.761985+00:00', try_number=1, map_index=-1)
2024-05-12 20:30:27,030 INFO - TaskInstance Finished: dag_id=extract_transform_load_data_dag, task_id=extract_data, run_id=manual__2024-05-12T15:30:03.761985+00:00, map_index=-1, run_start_date=2024-05-12 15:30:06.401434+00:00, run_end_date=2024-05-12 15:30:21.500229+00:00, run_duration=15.098795, state=failed, executor_state=success, try_number=1, max_tries=1, job_id=3, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-05-12 15:30:04.284419+00:00, queued_by_job_id=2, pid=12752
2024-05-12 20:30:29,509 ERROR - Marking run <DagRun extract_transform_load_data_dag @ 2024-05-12 15:30:03.761985+00:00: manual__2024-05-12T15:30:03.761985+00:00, state:running, queued_at: 2024-05-12 15:30:03.805513+00:00. externally triggered: True> failed
2024-05-12 20:30:29,510 INFO - DagRun Finished: dag_id=extract_transform_load_data_dag, execution_date=2024-05-12 15:30:03.761985+00:00, run_id=manual__2024-05-12T15:30:03.761985+00:00, run_start_date=2024-05-12 15:30:04.204563+00:00, run_end_date=2024-05-12 15:30:29.510404+00:00, run_duration=25.305841, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-05-12 15:30:03.761985+00:00, data_interval_end=2024-05-12 15:30:03.761985+00:00, dag_hash=5e688a83f4f070ff9a3ce5198a9303ec
2024-05-12 20:32:22,190 INFO - 1 tasks up for execution:
	<TaskInstance: extract_transform_load_data_dag.extract_data manual__2024-05-12T15:32:20.356671+00:00 [scheduled]>
2024-05-12 20:32:22,191 INFO - DAG extract_transform_load_data_dag has 0/16 running and queued tasks
2024-05-12 20:32:22,191 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_transform_load_data_dag.extract_data manual__2024-05-12T15:32:20.356671+00:00 [scheduled]>
2024-05-12 20:32:22,194 INFO - Sending TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='extract_data', run_id='manual__2024-05-12T15:32:20.356671+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-05-12 20:32:22,194 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'extract_data', 'manual__2024-05-12T15:32:20.356671+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:32:22,210 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'extract_data', 'manual__2024-05-12T15:32:20.356671+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:33:28,177 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='extract_data', run_id='manual__2024-05-12T15:32:20.356671+00:00', try_number=1, map_index=-1)
2024-05-12 20:33:28,179 INFO - TaskInstance Finished: dag_id=extract_transform_load_data_dag, task_id=extract_data, run_id=manual__2024-05-12T15:32:20.356671+00:00, map_index=-1, run_start_date=2024-05-12 15:32:24.270004+00:00, run_end_date=2024-05-12 15:33:27.791931+00:00, run_duration=63.521927, state=success, executor_state=success, try_number=1, max_tries=1, job_id=4, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-05-12 15:32:22.192906+00:00, queued_by_job_id=2, pid=13602
2024-05-12 20:33:28,190 ERROR - DagFileProcessorManager (PID=11716) last sent a heartbeat 66.05 seconds ago! Restarting it
2024-05-12 20:33:28,192 INFO - Sending Signals.SIGTERM to group 11716. PIDs of all processes in the group: [11716]
2024-05-12 20:33:28,192 INFO - Sending the signal Signals.SIGTERM to group 11716
2024-05-12 20:33:28,284 INFO - Process psutil.Process(pid=11716, status='terminated', exitcode=0, started='20:27:25') (11716) terminated with exit code 0
2024-05-12 20:33:28,289 INFO - Launched DagFileProcessorManager with pid: 14165
2024-05-12 20:33:28,295 INFO - Configured default timezone UTC
2024-05-12 20:33:28,343 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-12 20:33:28,612 INFO - 1 tasks up for execution:
	<TaskInstance: extract_transform_load_data_dag.transform_data manual__2024-05-12T15:32:20.356671+00:00 [scheduled]>
2024-05-12 20:33:28,613 INFO - DAG extract_transform_load_data_dag has 0/16 running and queued tasks
2024-05-12 20:33:28,613 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_transform_load_data_dag.transform_data manual__2024-05-12T15:32:20.356671+00:00 [scheduled]>
2024-05-12 20:33:28,614 INFO - Sending TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='transform_data', run_id='manual__2024-05-12T15:32:20.356671+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-05-12 20:33:28,615 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'transform_data', 'manual__2024-05-12T15:32:20.356671+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:33:28,625 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'transform_data', 'manual__2024-05-12T15:32:20.356671+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:33:31,191 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='transform_data', run_id='manual__2024-05-12T15:32:20.356671+00:00', try_number=1, map_index=-1)
2024-05-12 20:33:31,194 INFO - TaskInstance Finished: dag_id=extract_transform_load_data_dag, task_id=transform_data, run_id=manual__2024-05-12T15:32:20.356671+00:00, map_index=-1, run_start_date=2024-05-12 15:33:30.640088+00:00, run_end_date=2024-05-12 15:33:30.838462+00:00, run_duration=0.198374, state=success, executor_state=success, try_number=1, max_tries=1, job_id=5, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-05-12 15:33:28.613894+00:00, queued_by_job_id=2, pid=14193
2024-05-12 20:33:31,352 INFO - 1 tasks up for execution:
	<TaskInstance: extract_transform_load_data_dag.load_data manual__2024-05-12T15:32:20.356671+00:00 [scheduled]>
2024-05-12 20:33:31,352 INFO - DAG extract_transform_load_data_dag has 0/16 running and queued tasks
2024-05-12 20:33:31,353 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_transform_load_data_dag.load_data manual__2024-05-12T15:32:20.356671+00:00 [scheduled]>
2024-05-12 20:33:31,354 INFO - Sending TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='load_data', run_id='manual__2024-05-12T15:32:20.356671+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-05-12 20:33:31,354 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'load_data', 'manual__2024-05-12T15:32:20.356671+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:33:31,372 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'load_data', 'manual__2024-05-12T15:32:20.356671+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:34:09,923 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='load_data', run_id='manual__2024-05-12T15:32:20.356671+00:00', try_number=1, map_index=-1)
2024-05-12 20:34:09,926 INFO - TaskInstance Finished: dag_id=extract_transform_load_data_dag, task_id=load_data, run_id=manual__2024-05-12T15:32:20.356671+00:00, map_index=-1, run_start_date=2024-05-12 15:33:33.169274+00:00, run_end_date=2024-05-12 15:34:09.591521+00:00, run_duration=36.422247, state=success, executor_state=success, try_number=1, max_tries=1, job_id=6, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-05-12 15:33:31.353547+00:00, queued_by_job_id=2, pid=14218
2024-05-12 20:34:10,084 INFO - Marking run <DagRun extract_transform_load_data_dag @ 2024-05-12 15:32:20.356671+00:00: manual__2024-05-12T15:32:20.356671+00:00, state:running, queued_at: 2024-05-12 15:32:20.375800+00:00. externally triggered: True> successful
2024-05-12 20:34:10,084 INFO - DagRun Finished: dag_id=extract_transform_load_data_dag, execution_date=2024-05-12 15:32:20.356671+00:00, run_id=manual__2024-05-12T15:32:20.356671+00:00, run_start_date=2024-05-12 15:32:22.151890+00:00, run_end_date=2024-05-12 15:34:10.084608+00:00, run_duration=107.932718, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-05-12 15:32:20.356671+00:00, data_interval_end=2024-05-12 15:32:20.356671+00:00, dag_hash=5e688a83f4f070ff9a3ce5198a9303ec
2024-05-12 20:37:22,438 INFO - 1 tasks up for execution:
	<TaskInstance: extract_transform_load_data_dag.extract_data manual__2024-05-12T15:37:21.017119+00:00 [scheduled]>
2024-05-12 20:37:22,439 INFO - DAG extract_transform_load_data_dag has 0/16 running and queued tasks
2024-05-12 20:37:22,439 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_transform_load_data_dag.extract_data manual__2024-05-12T15:37:21.017119+00:00 [scheduled]>
2024-05-12 20:37:22,440 INFO - Sending TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='extract_data', run_id='manual__2024-05-12T15:37:21.017119+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-05-12 20:37:22,440 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'extract_data', 'manual__2024-05-12T15:37:21.017119+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:37:22,453 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'extract_data', 'manual__2024-05-12T15:37:21.017119+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:38:27,028 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='extract_data', run_id='manual__2024-05-12T15:37:21.017119+00:00', try_number=1, map_index=-1)
2024-05-12 20:38:27,030 INFO - TaskInstance Finished: dag_id=extract_transform_load_data_dag, task_id=extract_data, run_id=manual__2024-05-12T15:37:21.017119+00:00, map_index=-1, run_start_date=2024-05-12 15:37:24.704826+00:00, run_end_date=2024-05-12 15:38:26.589907+00:00, run_duration=61.885081, state=success, executor_state=success, try_number=1, max_tries=1, job_id=7, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-05-12 15:37:22.439710+00:00, queued_by_job_id=2, pid=15480
2024-05-12 20:38:27,041 ERROR - DagFileProcessorManager (PID=14165) last sent a heartbeat 64.65 seconds ago! Restarting it
2024-05-12 20:38:27,043 INFO - Sending Signals.SIGTERM to group 14165. PIDs of all processes in the group: [14165]
2024-05-12 20:38:27,043 INFO - Sending the signal Signals.SIGTERM to group 14165
2024-05-12 20:38:27,136 INFO - Process psutil.Process(pid=14165, status='terminated', exitcode=0, started='20:33:27') (14165) terminated with exit code 0
2024-05-12 20:38:27,141 INFO - Launched DagFileProcessorManager with pid: 16001
2024-05-12 20:38:27,147 INFO - Configured default timezone UTC
2024-05-12 20:38:27,452 INFO - 1 tasks up for execution:
	<TaskInstance: extract_transform_load_data_dag.transform_data manual__2024-05-12T15:37:21.017119+00:00 [scheduled]>
2024-05-12 20:38:27,452 INFO - DAG extract_transform_load_data_dag has 0/16 running and queued tasks
2024-05-12 20:38:27,452 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_transform_load_data_dag.transform_data manual__2024-05-12T15:37:21.017119+00:00 [scheduled]>
2024-05-12 20:38:27,454 INFO - Sending TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='transform_data', run_id='manual__2024-05-12T15:37:21.017119+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-05-12 20:38:27,454 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'transform_data', 'manual__2024-05-12T15:37:21.017119+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:38:27,465 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'transform_data', 'manual__2024-05-12T15:37:21.017119+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:38:29,771 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='transform_data', run_id='manual__2024-05-12T15:37:21.017119+00:00', try_number=1, map_index=-1)
2024-05-12 20:38:29,774 INFO - TaskInstance Finished: dag_id=extract_transform_load_data_dag, task_id=transform_data, run_id=manual__2024-05-12T15:37:21.017119+00:00, map_index=-1, run_start_date=2024-05-12 15:38:29.228843+00:00, run_end_date=2024-05-12 15:38:29.447100+00:00, run_duration=0.218257, state=success, executor_state=success, try_number=1, max_tries=1, job_id=8, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-05-12 15:38:27.453255+00:00, queued_by_job_id=2, pid=16010
2024-05-12 20:38:29,785 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-12 20:38:29,943 INFO - 1 tasks up for execution:
	<TaskInstance: extract_transform_load_data_dag.load_data manual__2024-05-12T15:37:21.017119+00:00 [scheduled]>
2024-05-12 20:38:29,944 INFO - DAG extract_transform_load_data_dag has 0/16 running and queued tasks
2024-05-12 20:38:29,944 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_transform_load_data_dag.load_data manual__2024-05-12T15:37:21.017119+00:00 [scheduled]>
2024-05-12 20:38:29,945 INFO - Sending TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='load_data', run_id='manual__2024-05-12T15:37:21.017119+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-05-12 20:38:29,945 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'load_data', 'manual__2024-05-12T15:37:21.017119+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:38:29,956 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_transform_load_data_dag', 'load_data', 'manual__2024-05-12T15:37:21.017119+00:00', '--local', '--subdir', '/home/awahab02/mlops_assignment_2/myenv/lib/python3.10/site-packages/airflow/example_dags/dagfile.py']
2024-05-12 20:38:43,475 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_transform_load_data_dag', task_id='load_data', run_id='manual__2024-05-12T15:37:21.017119+00:00', try_number=1, map_index=-1)
2024-05-12 20:38:43,478 INFO - TaskInstance Finished: dag_id=extract_transform_load_data_dag, task_id=load_data, run_id=manual__2024-05-12T15:37:21.017119+00:00, map_index=-1, run_start_date=2024-05-12 15:38:31.638652+00:00, run_end_date=2024-05-12 15:38:43.138290+00:00, run_duration=11.499638, state=success, executor_state=success, try_number=1, max_tries=1, job_id=9, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-05-12 15:38:29.944665+00:00, queued_by_job_id=2, pid=16049
2024-05-12 20:38:43,681 INFO - Marking run <DagRun extract_transform_load_data_dag @ 2024-05-12 15:37:21.017119+00:00: manual__2024-05-12T15:37:21.017119+00:00, state:running, queued_at: 2024-05-12 15:37:21.039283+00:00. externally triggered: True> successful
2024-05-12 20:38:43,681 INFO - DagRun Finished: dag_id=extract_transform_load_data_dag, execution_date=2024-05-12 15:37:21.017119+00:00, run_id=manual__2024-05-12T15:37:21.017119+00:00, run_start_date=2024-05-12 15:37:22.399947+00:00, run_end_date=2024-05-12 15:38:43.681799+00:00, run_duration=81.281852, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-05-12 15:37:21.017119+00:00, data_interval_end=2024-05-12 15:37:21.017119+00:00, dag_hash=5e688a83f4f070ff9a3ce5198a9303ec
